{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    \n",
    "    elif x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def create_database(min_value, max_value, d, number_of_points):\n",
    "    \"\"\"Creates a database of random points with a specified range and number of dimensions.\"\"\"\n",
    "    return np.random.uniform(min_value, max_value, (number_of_points, d + 2))\n",
    "\n",
    "def get_target_function(point1, point2):\n",
    "    \"\"\"Calculates the coefficients of the line passing through two random points.\"\"\"\n",
    "    a = (point2[1] - point1[1]) / (point2[0] - point1[0])  # Slope\n",
    "    b = point1[1] - a * point1[0]  # Intercept\n",
    "    return [a, b]\n",
    "\n",
    "def get_target_points(min_value, max_value, d):\n",
    "    \"\"\"Generates random points representing the endpoints of a line.\"\"\"\n",
    "    return np.random.uniform(min_value, max_value, (2, d))\n",
    "\n",
    "def is_above_line(point, coefficients):\n",
    "    \"\"\"Checks if a point is above a line defined by its coefficients.\"\"\"\n",
    "    return sign(point[1] - (coefficients[0] * point[0] + coefficients[1]))\n",
    "\n",
    "def target_function_to_database(database, coefficients):\n",
    "    \"\"\"Assigns labels to points in the database based on their position relative to a line.\"\"\"\n",
    "    for i in range(len(database)):\n",
    "        x = database[i][1]\n",
    "        y = database[i][2]\n",
    "\n",
    "        number_of_variables = database.shape[1]\n",
    "\n",
    "        database[i][0] = 1 # Add x0\n",
    "\n",
    "        database[i][number_of_variables - 1] = is_above_line([x, y], coefficients) # Add yn\n",
    "    \n",
    "    return database\n",
    "\n",
    "def calculate_divergence_probability(test_database, w):\n",
    "    real_values = test_database[:,3]\n",
    "    calculated_values = np.sign(test_database[:,:3] @  w)\n",
    "    equal_elements = calculated_values == real_values\n",
    "\n",
    "    return 1 - np.sum(equal_elements)/len(real_values)\n",
    "\n",
    "def pla(target_database, max_iterations, initial_w = None):\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    if initial_w:\n",
    "        w = initial_w\n",
    "    else: \n",
    "        w = np.array([0, 0, 0]) \n",
    "    while iterations < max_iterations:\n",
    "        iterations+=1\n",
    "        \n",
    "        misclassified_points_index = []\n",
    "\n",
    "        for i in range(len(target_database)):\n",
    "            point = target_database[i]\n",
    "            if sign(point[:3] @ w) != point[3]:\n",
    "                misclassified_points_index.append(i)\n",
    "        if len(misclassified_points_index) == 0: # Convergence\n",
    "            break\n",
    "\n",
    "       # print(misclassified_points_index)\n",
    "        \n",
    "        random_index = random.choice(misclassified_points_index)        \n",
    "        misclassified_point = target_database[random_index]\n",
    "\n",
    "        w = w + (misclassified_point[3] * misclassified_point[:3])\n",
    "    \n",
    "    return w,iterations   \n",
    "    \n",
    "def linear_regression(d,N):\n",
    "\n",
    "    database = create_database(-1,1,d,N)\n",
    "\n",
    "    target_points = get_target_points(-1, 1, d)\n",
    "    coefficients = get_target_function(target_points[0], target_points[1])\n",
    "\n",
    "    target_database = target_function_to_database(database, coefficients)\n",
    "\n",
    "    x = target_database[:,1]\n",
    "    y = target_database[:,2]\n",
    "\n",
    "\n",
    "    x_mean = np.mean(x)\n",
    "    y_mean = np.mean(y)\n",
    "\n",
    "    num = np.sum((x - x_mean) * (y - y_mean))\n",
    "    den = np.sum((x - x_mean) ** 2)\n",
    "\n",
    "    a = num / den\n",
    "    b = y_mean - a * x_mean\n",
    "\n",
    "    calculated_values = np.sign(y - (a*x + b))\n",
    "\n",
    "    real_values = database[:,3]\n",
    "\n",
    "    equal_elements = calculated_values == real_values\n",
    "\n",
    "    divergence_probability = 1 - np.sum(equal_elements)/len(real_values)\n",
    "    g = [a,b]\n",
    "    return g, divergence_probability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = create_database(-1,1,2,10)\n",
    "target_points = get_target_points(-1, 1, 2)\n",
    "coefficients = get_target_function(target_points[0], target_points[1])\n",
    "\n",
    "target_database = target_function_to_database(database, coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = target_database[:, 1]\n",
    "x2 = target_database[:, 2]\n",
    "categories = target_database[:, 3]\n",
    "\n",
    "# Colors by label\n",
    "colors = ['red' if category == -1 else 'blue' for category in categories]\n",
    "\n",
    "plt.scatter(x1, x2, c=colors, marker='o', label='Pontos')\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title('Função Target - f(x)')\n",
    "\n",
    "axes = plt.gca()\n",
    "x_vals = np.array(axes.get_xlim())\n",
    "y_vals = coefficients[1] + coefficients[0] * x_vals\n",
    "\n",
    "plt.plot(x_vals, y_vals, '--')\n",
    "\n",
    "plt.fill_between(x_vals, y_vals, plt.ylim()[0], color='lightcoral', alpha=0.5)\n",
    "\n",
    "plt.fill_between(x_vals, y_vals, plt.ylim()[1], color='skyblue', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,iteration = pla(target_database, 10000)\n",
    "\n",
    "test_database = create_database(-1,1,2,10000)\n",
    "target_test_database = target_function_to_database(test_database, coefficients)\n",
    "\n",
    "calculate_divergence_probability(target_test_database,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = test_database[:, 1]\n",
    "x2 = test_database[:, 2]\n",
    "categories = np.sign(target_test_database[:,:3] @  w)\n",
    "\n",
    "# Colors by label\n",
    "colors = ['red' if category == -1 else 'blue' for category in categories]\n",
    "\n",
    "plt.scatter(x1, x2, c=colors, marker='o', label='Pontos', s=2)\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "\n",
    "plt.xlabel('Eixo X')\n",
    "plt.ylabel('Eixo Y')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title('Hipótese g(x)')\n",
    "\n",
    "axes = plt.gca()\n",
    "x_vals = np.array(axes.get_xlim())\n",
    "y_vals = (-1*(w[0] + w[1]*x_vals))/w[2]\n",
    "\n",
    "\n",
    "plt.plot(x_vals, y_vals, '--')\n",
    "\n",
    "real_y_vals = coefficients[1] + coefficients[0] * x_vals\n",
    "\n",
    "\n",
    "\n",
    "plt.fill_between(x_vals, real_y_vals, plt.ylim()[0], color='lightcoral', alpha=0.5)\n",
    "\n",
    "plt.fill_between(x_vals, real_y_vals, plt.ylim()[1], color='skyblue', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = target_database[:,1]\n",
    "x2 =  target_database[:,2]\n",
    "categories = calculated_values\n",
    "\n",
    "# Colors by label\n",
    "colors = ['red' if category == -1 else 'blue' for category in categories]\n",
    "\n",
    "plt.scatter(x1, x2, c=colors, marker='o', label='Pontos', s=2)\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "\n",
    "\n",
    "plt.xlabel('Eixo X')\n",
    "plt.ylabel('Eixo Y')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.title('Hipótese g(x)')\n",
    "\n",
    "axes = plt.gca()\n",
    "x_vals = np.array(axes.get_xlim())\n",
    "y_vals = b + a * x_vals\n",
    "\n",
    "\n",
    "plt.plot(x_vals, y_vals, '--')\n",
    "\n",
    "real_y_vals = coefficients[1] + coefficients[0] * x_vals\n",
    "\n",
    "\n",
    "\n",
    "plt.fill_between(x_vals, real_y_vals, plt.ylim()[0], color='lightcoral', alpha=0.5)\n",
    "\n",
    "plt.fill_between(x_vals, real_y_vals, plt.ylim()[1], color='skyblue', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pla(d,N,max_iter,number_of_executions,test_size):\n",
    "\n",
    "    sum_divergence_probability=0\n",
    "    sum_iterations=0\n",
    "\n",
    "    for i in range(number_of_executions):\n",
    "        database = create_database(-1,1,d,N)\n",
    "\n",
    "        target_points = get_target_points(-1, 1, d)\n",
    "        coefficients = get_target_function(target_points[0], target_points[1])\n",
    "\n",
    "        target_database = target_function_to_database(database, coefficients)\n",
    "\n",
    "        w,iteration = pla(target_database, max_iter)\n",
    "        \n",
    "        test_database = create_database(-1,1,d,test_size)\n",
    "        target_test_database = target_function_to_database(test_database, coefficients)\n",
    "\n",
    "        divergence_probability = calculate_divergence_probability(target_test_database,w)\n",
    "\n",
    "        sum_divergence_probability+=divergence_probability\n",
    "        sum_iterations+=iteration\n",
    "    \n",
    "    return sum_divergence_probability/number_of_executions, sum_iterations/number_of_executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression(d,N,number_of_executions,test_size):\n",
    "\n",
    "    sum_error_inside=0\n",
    "    sum_error_outside=0\n",
    "\n",
    "    gs = {}\n",
    "\n",
    "    for i in range(number_of_executions):\n",
    "\n",
    "        g, error_inside = linear_regression(d,N)\n",
    "\n",
    "        test_database = create_database(-1,1,d,test_size)\n",
    "        target_test_database = target_function_to_database(test_database, coefficients)\n",
    "\n",
    "        x = target_test_database[:,1]\n",
    "        y = target_test_database[:,2]\n",
    "\n",
    "        a = g[0]\n",
    "        b = g[1]\n",
    "\n",
    "        calculated_values = np.sign(y - (a*x + b))\n",
    "\n",
    "        real_values = target_test_database[:,3]\n",
    "\n",
    "        equal_elements = calculated_values == real_values\n",
    "\n",
    "        error_outside = 1 - np.sum(equal_elements)/len(real_values)\n",
    "\n",
    "        gs[i] = g\n",
    "\n",
    "        sum_error_inside+=error_inside\n",
    "        sum_error_outside+=error_outside\n",
    "\n",
    "        \n",
    "    return sum_error_inside/number_of_executions, sum_error_outside/number_of_executions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_and_pla(d,N,max_iter,number_of_executions,test_size):\n",
    "\n",
    "    sum_divergence_probability=0\n",
    "    sum_iterations=0\n",
    "\n",
    "    for i in range(number_of_executions):\n",
    "        database = create_database(-1,1,d,N)\n",
    "\n",
    "        target_points = get_target_points(-1, 1, d)\n",
    "        coefficients = get_target_function(target_points[0], target_points[1])\n",
    "\n",
    "        target_database = target_function_to_database(database, coefficients)\n",
    "\n",
    "        w,iteration = pla(target_database, max_iter)\n",
    "        \n",
    "        test_database = create_database(-1,1,d,test_size)\n",
    "        target_test_database = target_function_to_database(test_database, coefficients)\n",
    "\n",
    "        divergence_probability = calculate_divergence_probability(target_test_database,w)\n",
    "\n",
    "        sum_divergence_probability+=divergence_probability\n",
    "        sum_iterations+=iteration\n",
    "    \n",
    "    return sum_divergence_probability/number_of_executions, sum_iterations/number_of_executions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLA for N = 10\n",
      "Mean Divergence Probability = 0.11130699999999993\n",
      "Mean Iterations = 9.607\n"
     ]
    }
   ],
   "source": [
    "mean_divergence_probability, mean_iterations = run_pla(d=2,N=10,max_iter=10000,number_of_executions=1000, test_size=10000)\n",
    "print(\"PLA for N = 10\")\n",
    "print(f\"Mean Divergence Probability = {mean_divergence_probability}\")\n",
    "print(f\"Mean Iterations = {mean_iterations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_divergence_probability, mean_iterations = run_pla(d=2,N=100,max_iter=10000,number_of_executions=1000, test_size=10000)\n",
    "print(\"PLA for N = 100\")\n",
    "print(f\"Mean Divergence Probability = {mean_divergence_probability}\")\n",
    "print(f\"Mean Iterations = {mean_iterations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a239277\\AppData\\Local\\Temp\\ipykernel_23284\\2853855742.py:25: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  equal_elements = calculated_values == real_values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PLA for N = 200\n",
      "Mean Divergence Probability = 0.3260500000000001\n",
      "Mean Iterations = 1.0\n"
     ]
    }
   ],
   "source": [
    "mean_divergence_probability, mean_iterations = run_pla(d=2,N=200,max_iter=10000,number_of_executions=1000, test_size=10000)\n",
    "print(\"PLA for N = 200\")\n",
    "print(f\"Mean Divergence Probability = {mean_divergence_probability}\")\n",
    "print(f\"Mean Iterations = {mean_iterations}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression for N = 100\n",
      "Mean Inside Error = 0.31458999999999965\n",
      "Mean Outside error = 0.24837400000000023\n"
     ]
    }
   ],
   "source": [
    "mean_error_inside, mean_error_outside = run_linear_regression(d=2,N=100,number_of_executions=1000, test_size=1000)\n",
    "print(\"Linear Regression for N = 100\")\n",
    "print(f\"Mean Inside Error = {mean_error_inside}\")\n",
    "print(f\"Mean Outside error = {mean_error_outside}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
